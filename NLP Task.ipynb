{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcce16c1-845c-42d7-b5a7-e2c5be930083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bc4494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 199s 11us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Helwan\\lib\\site-packages\\keras\\datasets\\imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\Anaconda\\envs\\Helwan\\lib\\site-packages\\keras\\datasets\\imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 31s 1ms/sample - loss: 0.6720 - accuracy: 0.5848 - val_loss: 0.6640 - val_accuracy: 0.6201\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 24s 964us/sample - loss: 0.6732 - accuracy: 0.5686 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 25s 1ms/sample - loss: 0.6843 - accuracy: 0.5353 - val_loss: 0.7081 - val_accuracy: 0.5204\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 24s 972us/sample - loss: 0.6852 - accuracy: 0.5399 - val_loss: 0.6877 - val_accuracy: 0.5178\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 25s 1ms/sample - loss: 0.6755 - accuracy: 0.5613 - val_loss: 0.6902 - val_accuracy: 0.5209\n",
      "25000/25000 [==============================] - 14s 560us/sample - loss: 0.6902 - accuracy: 0.5209\n",
      "Test Accuracy: 0.5209\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "num_words = 10000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
    "\n",
    "max_length = 200\n",
    "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
    "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=num_words, output_dim=128, input_length=max_length),\n",
    "    keras.layers.LSTM(64, return_sequences=True),\n",
    "    keras.layers.LSTM(32),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "def predict_sentiment(text, tokenizer, model, max_length=200):\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    prediction = model.predict(padded)[0][0]\n",
    "    return 'Positive' if prediction > 0.5 else 'Negative'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994583d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
